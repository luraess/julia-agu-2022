{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "_AGU 2022 - SCIWS26: Porting Machine Learning and Modeling from a Laptop to a Supercomputer_\n",
    "\n",
    "# Using Julia and GPU programming for numerical modelling\n",
    "\n",
    "#### Parallel high-performance stencil computations on xPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "#### Ludovic RÃ¤ss - ETHZ\n",
    "\n",
    "_with Sam Omlin (CSCS - ETHZ), Ivan Utkin (ETHZ)_\n",
    "\n",
    "![gpu](./figures/logo2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The nice to have features\n",
    "\n",
    "Wouldn't it be nice to have single code that on can:\n",
    "- run both on CPUs and GPUs (xPUs)?\n",
    "- run on laptops and supercomputers?\n",
    "- use for prototyping and production?\n",
    "- run at optimal performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hold on ðŸ™‚ ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why to bother with GPU computing\n",
    "\n",
    "A brief intro about GPU computing:\n",
    "- Why we do GPU computing\n",
    "- Why the Julia choice\n",
    "\n",
    "![gpu](./figures/gpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why we do GPU computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Predict the evolution of natural and engineered systems\n",
    "- e.g. ice cap evolution, stress distribution, etc...\n",
    "\n",
    "![ice2](./figures/ice2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Physical processes that describe those systems are **complex** and often **nonlinear**\n",
    "- no or very limited analytical solution is available\n",
    "\n",
    "ðŸ‘‰ a numerical approach is required to solve the mathematical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Computational costs increase\n",
    "- with complexity (e.g. multi-physics, coupling)\n",
    "- with dimensions (3D tensors...)\n",
    "- upon refining spatial and temporal resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![Stokes2D_vep](./figures/Stokes2D_vep.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Use **parallel computing** _(to address this)_\n",
    "- The \"memory wall\" in ~ 2004\n",
    "- Single-core to multi-core devices\n",
    "\n",
    "![mem_wall](./figures/mem_wall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "GPUs are massively parallel devices\n",
    "- SIMD machine (programmed using threads - SPMD) ([more](https://safari.ethz.ch/architecture/fall2020/lib/exe/fetch.php?media=onur-comparch-fall2020-lecture24-simdandgpu-afterlecture.pdf))\n",
    "- Further increases the Flop vs Bytes gap\n",
    "\n",
    "![cpu_gpu_evo](./figures/cpu_gpu_evo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Taking a look at a recent GPU and CPU:\n",
    "- Nvidia Tesla A100 GPU\n",
    "- AMD EPYC \"Rome\" 7282 (16 cores) CPU\n",
    "\n",
    "| Device         | TFLOP/s (FP64) | Memory BW TB/s |\n",
    "| :------------: | :------------: | :------------: |\n",
    "| Tesla A100     | 9.7            | 1.55           |\n",
    "| AMD EPYC 7282  | 0.7            | 0.085          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Current GPUs (and CPUs) can do many more computations in a given amount of time than they can access numbers from main memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quantify the imbalance:\n",
    "\n",
    "$$ \\frac{\\mathrm{computation\\;peak\\;perf.\\;[TFLOP/s]}}{\\mathrm{memory\\;access\\;peak\\;perf.\\;[TB/s]}} Ã— \\mathrm{size\\;of\\;a\\;number\\;[Bytes]} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_(Theoretical peak performance values as specified by the vendors can be used)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Back to our hardware:\n",
    "\n",
    "| Device         | TFLOP/s (FP64) | Memory BW TB/s | Imbalance (FP64)     |\n",
    "| :------------: | :------------: | :------------: | :------------------: |\n",
    "| Tesla A100     | 9.7            | 1.55           | 9.7 / 1.55  Ã— 8 = 50 |\n",
    "| AMD EPYC 7282  | 0.7            | 0.085          | 0.7 / 0.085 Ã— 8 = 66 |\n",
    "\n",
    "\n",
    "_(here computed with double precision values)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Meaning:** we can do about 50 floating point operations per number accessed from main memory. Floating point operations are \"for free\" when we work in memory-bounded regimes.\n",
    "\n",
    "ðŸ‘‰ Requires to re-think the numerical implementation and solution strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Unfortunately, the cost of evaluating a first derivative $âˆ‚A / âˆ‚x$ using finite-differences consists of:\n",
    "\n",
    "1 reads + 1 write => $2 Ã— 8$ = **16 Bytes transferred**\n",
    "\n",
    "1 (fused) addition and division => **1 floating point operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to evaluate performance\n",
    "\n",
    "_The FLOP/s metric is no longer the most adequate for reporting the application performance of many modern applications on modern hardware._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Effective memory throughput metric $T_\\mathrm{eff}$\n",
    "\n",
    "Need for a memory throughput-based performance metric: $T_\\mathrm{eff}$ [GiB/s]\n",
    "\n",
    "âž¡  Evaluate the performance of iterative stencil-based solvers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The effective memory access $A_\\mathrm{eff}$ [GiB], is the sum of:\n",
    "- twice the memory footprint of the unknown fields, $D_\\mathrm{u}$, (fields that depend on their own history and that need to be updated every iteration)\n",
    "- known fields, $D_\\mathrm{k}$, that do not change every iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The effective memory access divided by the execution time per iteration, $t_\\mathrm{it}$ [sec], defines the effective memory throughput, $T_\\mathrm{eff}$ [GiB/s]:\n",
    "\n",
    "$$ A_\\mathrm{eff} = 2~D_\\mathrm{u} + D_\\mathrm{k}, \\;\\;\\; T_\\mathrm{eff} = \\frac{A_\\mathrm{eff}}{t_\\mathrm{it}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> ðŸ’¡ note: The upper bound of $T_\\mathrm{eff}$ is $T_\\mathrm{peak}$ as measured, e.g., by [McCalpin, 1995](https://www.researchgate.net/publication/51992086_Memory_bandwidth_and_machine_balance_in_high_performance_computers) for CPUs or a GPU analogue.\n",
    ">\n",
    "> Defining the $T_\\mathrm{eff}$ metric, we assume that:\n",
    "> 1. we evaluate an iterative stencil-based solver,\n",
    "> 2. the problem size is much larger than the cache sizes and\n",
    ">\n",
    "> All \"convenience\" fields should not be stored and can be re-computed on the fly or stored on-chip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why the Julia choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Julia + GPUs  âž¡  close to **1 TB/s** memory throughput\n",
    "\n",
    "Julia + GPUs + MPI  âž¡  close to **94%** parallel efficiency on 2000+ GPUs\n",
    "\n",
    "![perf_gpu](./figures/ps_igg_perf.png)\n",
    "\n",
    "**And one can get there** ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Solution to the \"two-language problem\"\n",
    "\n",
    "![two_lang](./figures/two_lang.png)\n",
    "\n",
    "Single code for prototyping and production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Backend agnostic:\n",
    "- Single code to run on single CPU or thousands of GPUs\n",
    "- Single code to run on various CPUs (x86, ARM, Power9, ...) \\\n",
    "  and GPUs (Nvidia, AMD, Intel?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Interactive:\n",
    "- No need for third-party visualisation software\n",
    "- Debugging and interactive REPL mode\n",
    "- Efficient for development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "too good to be true?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![ParallelStencil](./figures/parallelstencil.png)\n",
    "\n",
    "\n",
    "[https://github.com/omlins/ParallelStencil.jl](https://github.com/omlins/ParallelStencil.jl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Enough propaganda\n",
    "Let's check out [ParallelStencil.jl](https://github.com/omlins/ParallelStencil.jl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'll solve the heat diffusion equation\n",
    "\n",
    "$$ c \\frac{âˆ‚T}{âˆ‚t} = âˆ‡â‹…Î» âˆ‡T $$\n",
    "\n",
    "using explicit 2D finite-differences on a Cartesian staggered grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ðŸ‘‰ This notebook is available on GitHub: [https://github.com/luraess/julia-agu-2022](https://github.com/luraess/julia-agu-2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Heat solver implementations and performance evaluation\n",
    "\n",
    "1. Array programming and broadcasting (vectorised Julia CPU)\n",
    "2. Array programming and broadcasting (vectorised Julia GPU)\n",
    "3. Kernel programming using ParallelStencil with math-close notation (`FiniteDifferences` module)\n",
    "\n",
    "**Goal:** get as close as possible to GPU's peak performance, 1355 GiB/s for the Nvidia Tesla A100 GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setting up the environment\n",
    "\n",
    "Before we start, let's activate the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.resolve()\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add the package(s) we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, CUDA, BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Array programming on CPU\n",
    "\n",
    "$$ c \\frac{âˆ‚T}{âˆ‚t} = âˆ‡â‹…Î» âˆ‡T $$\n",
    "\n",
    "A 24 lines code including visualisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function diffusion2D()\n",
    "    # Physics\n",
    "    Î»      = 1.0                                           # Thermal conductivity\n",
    "    c0     = 1.0                                           # Heat capacity\n",
    "    lx, ly = 10.0, 10.0                                    # Length of computational domain in dimension x and y\n",
    "    # Numerics\n",
    "    nx, ny = 32*2, 32*2                                    # Number of grid points in dimensions x and y\n",
    "    nt     = 100                                           # Number of time steps\n",
    "    dx, dy = lx/(nx-1), ly/(ny-1)                          # Space step in x and y-dimension\n",
    "    # Array initializations\n",
    "    T      = zeros(Float64,nx  ,ny  )                      # Temperature\n",
    "    Ci     = zeros(Float64,nx  ,ny  )                      # 1/Heat capacity\n",
    "    qTx    = zeros(Float64,nx-1,ny-2)                      # Heat flux in x-dim\n",
    "    qTy    = zeros(Float64,nx-2,ny-1)                      # Heat flux in y-dim\n",
    "    # Initial conditions\n",
    "    Ci    .= 1.0/c0                                        # 1/Heat capacity (could vary in space)\n",
    "    T     .= [exp(-(((ix-1)*dx-lx/2)/2)^2-(((iy-1)*dy-ly/2)/2)^2) for ix=1:size(T,1), iy=1:size(T,2)] # Initial Gaussian Temp\n",
    "    # Time loop\n",
    "    dt     = min(dx^2,dy^2)/Î»/maximum(Ci)/4.1              # Time step for 2D Heat diffusion\n",
    "    opts   = (aspect_ratio=1,xlims=(1,nx),ylims=(1,ny),clims=(0.0,1.0),c=:turbo,xlabel=\"Lx\",ylabel=\"Ly\") # plotting options\n",
    "    @gif for it = 1:nt\n",
    "        qTx .= .-Î» .* diff(T[:,2:end-1],dims=1)./dx\n",
    "        qTy .= .-Î» .* diff(T[2:end-1,:],dims=2)./dy\n",
    "        T[2:end-1,2:end-1] .+= dt.*Ci[2:end-1,2:end-1].*(.-diff(qTx,dims=1)./dx .-diff(qTy,dims=2)./dy)\n",
    "        heatmap(Array(T)',title=\"it=$it\"; opts...)        # Visualization\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example runs on the CPU. What if we want to execute it on the GPU?\n",
    "\n",
    "### 2. Array programming on GPU\n",
    "\n",
    "In Julia, this is pretty simple as we can use the [CUDA.jl](https://github.com/JuliaGPU/CUDA.jl) package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and add initialise our arrays as `CuArray`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function diffusion2D()\n",
    "    # Physics\n",
    "    Î»      = 1.0                                           # Thermal conductivity\n",
    "    c0     = 1.0                                           # Heat capacity\n",
    "    lx, ly = 10.0, 10.0                                    # Length of computational domain in dimension x and y\n",
    "    # Numerics\n",
    "    nx, ny = 32*2, 32*2                                    # Number of grid points in dimensions x and y\n",
    "    nt     = 100                                           # Number of time steps\n",
    "    dx, dy = lx/(nx-1), ly/(ny-1)                          # Space step in x and y-dimension\n",
    "    # Array initializations\n",
    "    T      = CUDA.zeros(Float64,nx  ,ny  )                 # Temperature\n",
    "    Ci     = CUDA.zeros(Float64,nx  ,ny  )                 # 1/Heat capacity\n",
    "    qTx    = CUDA.zeros(Float64,nx-1,ny-2)                 # Heat flux in x-dim\n",
    "    qTy    = CUDA.zeros(Float64,nx-2,ny-1)                 # Heat flux in y-dim\n",
    "    # Initial conditions\n",
    "    Ci    .= 1.0/c0                                        # 1/Heat capacity (could vary in space)\n",
    "    T     .= CuArray([exp(-(((ix-1)*dx-lx/2)/2)^2-(((iy-1)*dy-ly/2)/2)^2) for ix=1:size(T,1), iy=1:size(T,2)]) # Initial Gaussian Temp\n",
    "    # Time loop\n",
    "    dt     = min(dx^2,dy^2)/Î»/maximum(Ci)/4.1              # Time step for 2D Heat diffusion\n",
    "    opts   = (aspect_ratio=1,xlims=(1,nx),ylims=(1,ny),clims=(0.0,1.0),c=:turbo,xlabel=\"Lx\",ylabel=\"Ly\") # plotting options\n",
    "    @gif for it = 1:nt\n",
    "        qTx .= .-Î» .* diff(T[:,2:end-1],dims=1)./dx\n",
    "        qTy .= .-Î» .* diff(T[2:end-1,:],dims=2)./dy\n",
    "        T[2:end-1,2:end-1] .+= dt.*Ci[2:end-1,2:end-1].*(.-diff(qTx,dims=1)./dx .-diff(qTy,dims=2)./dy)\n",
    "        heatmap(Array(T)',title=\"it=$it\"; opts...)        # Visualization\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, so it runs on the GPU now. But how much faster - what did we gain? Let's determine the effective memory throughput $T_\\mathrm{eff}$ for both implementations.\n",
    "\n",
    "### CPU vs GPU array programming performance\n",
    "\n",
    "For this, we can isolate the physics computation into a function that we will evaluate for benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function update_temperature!(T, qTx, qTy, Ci, Î», dt, dx, dy)\n",
    "    @inbounds qTx .= .-Î» .* diff(T[:,2:end-1],dims=1)./dx\n",
    "    @inbounds qTy .= .-Î» .* diff(T[2:end-1,:],dims=2)./dy\n",
    "    @inbounds T[2:end-1,2:end-1] .+= dt.*Ci[2:end-1,2:end-1].*(.-diff(qTx,dims=1)./dx .-diff(qTy,dims=2)./dy)\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, for benchmarking activities, we will require the following arrays and scalars and make sure to use sufficiently large arrays in order to saturate the memory bandwidth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = ny = 512*32\n",
    "T   = rand(Float64,nx  ,ny  )\n",
    "Ci  = rand(Float64,nx  ,ny  )\n",
    "qTx = rand(Float64,nx-1,ny-2)\n",
    "qTy = rand(Float64,nx-2,ny-1)\n",
    "Î» = dx = dy = dt = rand();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use `@belapsed` macro from [BenchmarkTools](https://github.com/JuliaCI/BenchmarkTools.jl) to sample our perf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_it = @belapsed begin update_temperature!($T, $qTx, $qTy, $Ci, $Î», $dt, $dx, $dy); end\n",
    "T_eff_cpu_bcast = (2*1+1)/1e9*nx*ny*sizeof(Float64)/t_it\n",
    "println(\"T_eff = $(T_eff_cpu_bcast) GiB/s using CPU array programming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the experiment using the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = ny = 512*32\n",
    "T   = CUDA.rand(Float64,nx  ,ny  )\n",
    "Ci  = CUDA.rand(Float64,nx  ,ny  )\n",
    "qTx = CUDA.rand(Float64,nx-1,ny-2)\n",
    "qTy = CUDA.rand(Float64,nx-2,ny-1)\n",
    "Î» = dx = dy = dt = rand();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And sample again our performance from the GPU execution this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_it = @belapsed begin update_temperature!($T, $qTx, $qTy, $Ci, $Î», $dt, $dx, $dy); synchronize(); end\n",
    "T_eff_gpu_bcast = (2*1+1)/1e9*nx*ny*sizeof(Float64)/t_it\n",
    "println(\"T_eff = $(T_eff_gpu_bcast) GiB/s using GPU array programming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some improvement from performing the computations on the GPU, however, $T_\\mathrm{eff}$ is not yet close to GPU's peak memory bandwidth\n",
    "\n",
    "How to improve? Now it's time for ParallelStencil\n",
    "\n",
    "### 3. Kernel programming using ParallelStencil\n",
    "\n",
    "In this first example, we'll use the `FiniteDifferences` module to enable math-close notation and the `CUDA` \"backend\". We could simply switch the backend to `Threads` if we want the same code to run on multiple CPU threads using Julia's native multi-threading capabilities. But for time issues, we won't investigate this today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU=true\n",
    "using ParallelStencil\n",
    "using ParallelStencil.FiniteDifferences2D\n",
    "@static if USE_GPU\n",
    "    @init_parallel_stencil(CUDA, Float64, 2)\n",
    "    CUDA.device!(7) # select specific GPU\n",
    "else\n",
    "    @init_parallel_stencil(Threads, Float64, 2)\n",
    "end\n",
    "nx = ny = 512*64\n",
    "T   = @rand(nx  ,ny  )\n",
    "Ci  = @rand(nx  ,ny  )\n",
    "qTx = @rand(nx-1,ny-2)\n",
    "qTy = @rand(nx-2,ny-1)\n",
    "Î» = dx = dy = dt = rand();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using math-close notations from the `FiniteDifferences2D` module, our update kernel can be re-written as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@parallel function update_temperature_ps!(T, qTx, qTy, Ci, Î», dt, dx, dy)\n",
    "    @all(qTx) = -Î» * @d_xi(T)/dx\n",
    "    @all(qTy) = -Î» * @d_yi(T)/dy\n",
    "    @inn(T)   = @inn(T) + dt*@inn(Ci)*(-@d_xa(qTx)/dx -@d_ya(qTy)/dy)\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And sample again our performance on the GPU using ParallelStencil this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_it = @belapsed begin @parallel update_temperature_ps!($T, $qTx, $qTy, $Ci, $Î», $dt, $dx, $dy); end\n",
    "T_eff_ps = (2*1+1)/1e9*nx*ny*sizeof(Float64)/t_it\n",
    "println(\"T_eff = $(T_eff_ps) GiB/s using ParallelStencil on GPU and the FiniteDifferences2D module\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's already much better, but we can do more in order to approach the peak memory bandwidth of the GPU - 1355 GiB/s for the Nvidia Tesla A100.\n",
    "\n",
    "We should now remove the convenience arrays `qTx`, `qTy` (no time dependence), as these intermediate storage add pressure on the memory bandwidth which slows down the calculations since we are memory-bound.\n",
    "We can rewrite it as following assuming that `Î»` is constant (a scalar here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@parallel function update_temperature_ps2!(T2, T, Ci, Î», dt, dx, dy)\n",
    "    @inn(T2) = @inn(T) + dt*Î»*@inn(Ci)*(@d2_xi(T)/dx/dx + @d2_yi(T)/dy/dy)\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sample again our performance on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2 = copy(T)\n",
    "t_it = @belapsed begin @parallel update_temperature_ps2!($T2, $T, $Ci, $Î», $dt, $dx, $dy); end\n",
    "T_eff_ps2 = (2*1+1)*1/1e9*nx*ny*sizeof(Float64)/t_it\n",
    "println(\"T_eff = $(T_eff_ps2) GiB/s using ParallelStencil on GPU without convenience arrays\")\n",
    "println(\"So, we made it. Our 2D diffusion kernel runs on the GPU at $(T_eff_psind/1355) % of memory copy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's cool. We are getting close to hardware limit ðŸš€\n",
    "\n",
    "> ðŸ’¡ note: We need a buffer array now in order to avoid race conditions and erroneous results when accessing the `T` array in parallel.\n",
    "\n",
    "Time to recap what we've seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "- Starting with performance, we can now clearly see our 4 data points of $T_\\mathrm{eff}$ and how close the GPU performance is from the peak memory bandwidth of the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xPU  = (\"CPU-AP\", \"GPU-AP\", \"GPU-PS\", \"GPU-PS2\")\n",
    "Teff = [T_eff_cpu_bcast, T_eff_gpu_bcast, T_eff_ps, T_eff_ps2]\n",
    "plot(Teff,ylabel=\"T_eff [GiB/s]\",xlabel=\"implementation\",xticks=(1:length(xPU),xPU),xaxis=([0.7, 4.3]),linewidth=0,markershape=:square,markersize=8,legend=false,fontfamily=\"Courier\",framestyle=:box)\n",
    "plot!([0.7,4.3],[1355,1355],linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Julia and ParallelStencil permit to solve the two-language problem\n",
    "- ParallelStencil and Julia GPU permit to exploit close to GPUs' peak memory throughput\n",
    "\n",
    "![parallelstencil](./figures/parallelstencil.png)\n",
    "\n",
    "Wanna more? Check out [https://github.com/omlins/ParallelStencil.jl](https://github.com/omlins/ParallelStencil.jl) and the [miniapps](https://github.com/omlins/ParallelStencil.jl#concise-singlemulti-xpu-miniapps)\n",
    "\n",
    "Advance features not covered today:\n",
    "- Using shared-memory and 2.5D blocking (see [here](https://github.com/omlins/ParallelStencil.jl#support-for-architecture-agnostic-low-level-kernel-programming) with [example](https://github.com/omlins/ParallelStencil.jl/blob/main/examples/diffusion2D_shmem_novis.jl))\n",
    "- Multi-GPU with communication-computation overlap combining ParallelStencil and [ImplicitGlobalGrid]()\n",
    "- Stay tuned, AMDGPU support is coming soon ðŸš€\n",
    "- Enjoy reading? Check out\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "\n",
    "_contact: luraess@ethz.ch_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
